{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import time\n",
    "from nltk.corpus import words\n",
    "from textblob import TextBlob\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,TfidfTransformer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(143570, 2)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 14 - Model 1\n",
    "# 22 - Model 2\n",
    "# 21 - DataSet\n",
    "\n",
    "# set the path of the data set 1 (dataset which created using real time data)\n",
    "df1 = pd.read_csv(\"Twylist Telecom Dataset.csv\" ,header = None)\n",
    "\n",
    "# 143570 data\n",
    "df1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name the columns\n",
    "df1.columns = ['date', 'tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words in different grammatical categories convert into one common root. \n",
    "\n",
    "def text_lemmatizer(text):\n",
    "  # This function is used to lemmatize the given sentence\n",
    "    lemmatizer =  WordNetLemmatizer ()\n",
    "    token_words = word_tokenize(text)\n",
    "    stem_sentence = []\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(lemmatizer.lemmatize(word))\n",
    "    return \" \".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters from the tweet\n",
    "def clean_text(tweet):\n",
    "    \n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # have to remove \"b'RT @endaburke81\" at the begining of the tweet\n",
    "    if(tweet[:4]==\"b'rt\"):\n",
    "        tweet = tweet.split(\":\", 1)[1]\n",
    "\n",
    "    # splitting the tweet\n",
    "    tweet = tweet.split()\n",
    "    \n",
    "    # Joining the tweet\n",
    "    tweet = \" \".join(tweet)\n",
    "    \n",
    "    #Removing digits and numbers\n",
    "    tweet = \"\".join([i for i in tweet if not i.isdigit()])\n",
    "    \n",
    "    # Removing special characters from the tweet\n",
    "    tweet = re.sub(f'[{re.escape(string.punctuation)}]', \"\", tweet)\n",
    "    \n",
    "    # cleaning = nltk.tokenize.wordpunct_tokenize(tweet)\n",
    "    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) if w.lower() in words or not w.isalpha())\n",
    "    \n",
    "    tweet = text_lemmatizer(tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding cleaning method\n",
    "df1[\"tweet_clean\"] = df1[\"tweet\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                  date                                              tweet  \\\n0  2021-03-25 04:55:11  b'RT @Zahrah03959662: Parvez Abbasi- Telecom v...   \n1  2021-03-25 04:54:58  b'RT @Zahrah03959662: Zouhair Khaliq IT &amp; ...   \n2  2021-03-25 04:54:31  b'RT @Shah28Adil: Zouhair is a business execut...   \n3  2021-03-25 04:53:23  b'Zouhair Khaliq IT &amp; Telecom, Co-Founder ...   \n4  2021-03-25 04:53:12  b'Welcome! You are invited to join a webinar: ...   \n\n                                         tweet_clean sentiment   polarity  \n0  abbasi veteran project director national incub...  negative -0.0333333  \n1  it cofounder partner at team up group is a bus...   neutral          0  \n2  is a business executive with global experience...   neutral          0  \n3  it cofounder partner at team up group is a bus...   neutral          0  \n4    you are to join a editorial learning by doing g   neutral          0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>tweet</th>\n      <th>tweet_clean</th>\n      <th>sentiment</th>\n      <th>polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-03-25 04:55:11</td>\n      <td>b'RT @Zahrah03959662: Parvez Abbasi- Telecom v...</td>\n      <td>abbasi veteran project director national incub...</td>\n      <td>negative</td>\n      <td>-0.0333333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-03-25 04:54:58</td>\n      <td>b'RT @Zahrah03959662: Zouhair Khaliq IT &amp;amp; ...</td>\n      <td>it cofounder partner at team up group is a bus...</td>\n      <td>neutral</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-03-25 04:54:31</td>\n      <td>b'RT @Shah28Adil: Zouhair is a business execut...</td>\n      <td>is a business executive with global experience...</td>\n      <td>neutral</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-03-25 04:53:23</td>\n      <td>b'Zouhair Khaliq IT &amp;amp; Telecom, Co-Founder ...</td>\n      <td>it cofounder partner at team up group is a bus...</td>\n      <td>neutral</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-03-25 04:53:12</td>\n      <td>b'Welcome! You are invited to join a webinar: ...</td>\n      <td>you are to join a editorial learning by doing g</td>\n      <td>neutral</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentiment analysis using polarity\n",
    "\n",
    "df1['sentiment'] = ' '\n",
    "df1['polarity'] = None\n",
    "for i,tweets in enumerate(df1.tweet_clean) :\n",
    "    blob = TextBlob(tweets)\n",
    "    df1['polarity'][i] = blob.sentiment.polarity\n",
    "    if blob.sentiment.polarity > 0 :\n",
    "        df1['sentiment'][i] = 'positive'\n",
    "    elif blob.sentiment.polarity < 0 :\n",
    "        df1['sentiment'][i] = 'negative'\n",
    "    else :\n",
    "        df1['sentiment'][i] = 'neutral'\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(67359, 5)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicate data from dataset 1\n",
    "df1=df1.drop_duplicates(subset='tweet', keep=\"last\")\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(20867, 5)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive data count\n",
    "df1.loc[df1['sentiment'] == \"positive\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(12002, 5)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative data count\n",
    "df1.loc[df1['sentiment'] == \"negative\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(34490, 5)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neutral data count\n",
    "df1.loc[df1['sentiment'] == \"neutral\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                       date  \\\n1       2021-03-25 04:54:58   \n3       2021-03-25 04:53:23   \n4       2021-03-25 04:53:12   \n6       2021-03-25 04:52:59   \n8       2021-03-25 04:52:18   \n...                     ...   \n143565  2021-03-21 03:53:57   \n143566  2021-03-21 03:53:55   \n143567  2021-03-21 03:53:55   \n143568  2021-03-21 03:53:54   \n143569  2021-03-21 03:53:53   \n\n                                                    tweet  \\\n1       b'RT @Zahrah03959662: Zouhair Khaliq IT &amp; ...   \n3       b'Zouhair Khaliq IT &amp; Telecom, Co-Founder ...   \n4       b'Welcome! You are invited to join a webinar: ...   \n6       b'Engage with your customers in real-time with...   \n8       b'@JioCare 1.44 mbps..??? Your 4g speed \\xf0\\x...   \n...                                                   ...   \n143565           b'@enptg GOD THE FUCKING WIFI#@%*#)*%#)'   \n143566  b'We don\\xe2\\x80\\x99t accept internet shutdown...   \n143567  b'nobody\\xe2\\x80\\x99s wifi is working in the h...   \n143568  b'RT @KhaingEiKhaing: It\\xe2\\x80\\x99s been 7da...   \n143569  b'RT @iotcybersec24: \\xf0\\x9f\\x91\\x89 $154.99 ...   \n\n                                              tweet_clean sentiment  polarity  \n1       it cofounder partner at team up group is a bus...   neutral         0  \n3       it cofounder partner at team up group is a bus...   neutral         0  \n4         you are to join a editorial learning by doing g   neutral         0  \n6       with your in with our and measure your perform...   neutral         0  \n8          your g speed hopefully you care about the also   neutral         0  \n...                                                   ...       ...       ...  \n143565                                            god the   neutral         0  \n143566  accept shutdown we dun accept news suppression...  positive       0.5  \n143567  is working in the house except for on my phone...   neutral         0  \n143568  been day since the military junta cut off mobi...  positive  0.133333  \n143569                smart router tri band router server  positive  0.214286  \n\n[67359 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>tweet</th>\n      <th>tweet_clean</th>\n      <th>sentiment</th>\n      <th>polarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2021-03-25 04:54:58</td>\n      <td>b'RT @Zahrah03959662: Zouhair Khaliq IT &amp;amp; ...</td>\n      <td>it cofounder partner at team up group is a bus...</td>\n      <td>neutral</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-03-25 04:53:23</td>\n      <td>b'Zouhair Khaliq IT &amp;amp; Telecom, Co-Founder ...</td>\n      <td>it cofounder partner at team up group is a bus...</td>\n      <td>neutral</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-03-25 04:53:12</td>\n      <td>b'Welcome! You are invited to join a webinar: ...</td>\n      <td>you are to join a editorial learning by doing g</td>\n      <td>neutral</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2021-03-25 04:52:59</td>\n      <td>b'Engage with your customers in real-time with...</td>\n      <td>with your in with our and measure your perform...</td>\n      <td>neutral</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2021-03-25 04:52:18</td>\n      <td>b'@JioCare 1.44 mbps..??? Your 4g speed \\xf0\\x...</td>\n      <td>your g speed hopefully you care about the also</td>\n      <td>neutral</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>143565</th>\n      <td>2021-03-21 03:53:57</td>\n      <td>b'@enptg GOD THE FUCKING WIFI#@%*#)*%#)'</td>\n      <td>god the</td>\n      <td>neutral</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>143566</th>\n      <td>2021-03-21 03:53:55</td>\n      <td>b'We don\\xe2\\x80\\x99t accept internet shutdown...</td>\n      <td>accept shutdown we dun accept news suppression...</td>\n      <td>positive</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>143567</th>\n      <td>2021-03-21 03:53:55</td>\n      <td>b'nobody\\xe2\\x80\\x99s wifi is working in the h...</td>\n      <td>is working in the house except for on my phone...</td>\n      <td>neutral</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>143568</th>\n      <td>2021-03-21 03:53:54</td>\n      <td>b'RT @KhaingEiKhaing: It\\xe2\\x80\\x99s been 7da...</td>\n      <td>been day since the military junta cut off mobi...</td>\n      <td>positive</td>\n      <td>0.133333</td>\n    </tr>\n    <tr>\n      <th>143569</th>\n      <td>2021-03-21 03:53:53</td>\n      <td>b'RT @iotcybersec24: \\xf0\\x9f\\x91\\x89 $154.99 ...</td>\n      <td>smart router tri band router server</td>\n      <td>positive</td>\n      <td>0.214286</td>\n    </tr>\n  </tbody>\n</table>\n<p>67359 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the undefined tweets\n",
    "df1 = df1.loc[df1['sentiment'] != \"\"]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted columns to equalise two data sets\n",
    "df1.drop(['date','tweet','polarity'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                              tweet_clean sentiment\n1       it cofounder partner at team up group is a bus...   neutral\n3       it cofounder partner at team up group is a bus...   neutral\n4         you are to join a editorial learning by doing g   neutral\n6       with your in with our and measure your perform...   neutral\n8          your g speed hopefully you care about the also   neutral\n...                                                   ...       ...\n143565                                            god the   neutral\n143566  accept shutdown we dun accept news suppression...  positive\n143567  is working in the house except for on my phone...   neutral\n143568  been day since the military junta cut off mobi...  positive\n143569                smart router tri band router server  positive\n\n[67359 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_clean</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>it cofounder partner at team up group is a bus...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>it cofounder partner at team up group is a bus...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>you are to join a editorial learning by doing g</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>with your in with our and measure your perform...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>your g speed hopefully you care about the also</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>143565</th>\n      <td>god the</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>143566</th>\n      <td>accept shutdown we dun accept news suppression...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>143567</th>\n      <td>is working in the house except for on my phone...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>143568</th>\n      <td>been day since the military junta cut off mobi...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>143569</th>\n      <td>smart router tri band router server</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>67359 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path of the data set 2 \n",
    "df2 = pd.read_csv(\"Telecom Dataset.csv\" )\n",
    "# Add the cleaning method\n",
    "df2[\"tweet_clean\"] = df2[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Unnamed: 0        Category  Label  \\\n0           0    Poor service      4   \n1           1    Poor service      4   \n2           2    Poor service      4   \n3           3  Happy Customer      2   \n4           4  Happy Customer      2   \n\n                                                text  \\\n0  @VZWSupport Give me a working phone without ha...   \n1  @verizon, my daughter and I both have #Verizon...   \n2  Verizon  customer service is the worst. I drea...   \n3  I love having Verizon. I get service just abou...   \n4  Great service from @VZWSupport and @SamsungSup...   \n\n                                         tweet_clean sentiment  \n0  give me a working phone without me jump throug...  negative  \n1  my daughter and i both have and we keep our fa...  negative  \n2  customer service is the worst i dread to ever ...  negative  \n3           i love i get service just about anywhere  positive  \n4  great service from and tonight really quality ...  positive  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Category</th>\n      <th>Label</th>\n      <th>text</th>\n      <th>tweet_clean</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Poor service</td>\n      <td>4</td>\n      <td>@VZWSupport Give me a working phone without ha...</td>\n      <td>give me a working phone without me jump throug...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Poor service</td>\n      <td>4</td>\n      <td>@verizon, my daughter and I both have #Verizon...</td>\n      <td>my daughter and i both have and we keep our fa...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Poor service</td>\n      <td>4</td>\n      <td>Verizon  customer service is the worst. I drea...</td>\n      <td>customer service is the worst i dread to ever ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Happy Customer</td>\n      <td>2</td>\n      <td>I love having Verizon. I get service just abou...</td>\n      <td>i love i get service just about anywhere</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Happy Customer</td>\n      <td>2</td>\n      <td>Great service from @VZWSupport and @SamsungSup...</td>\n      <td>great service from and tonight really quality ...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This data set categorize for 4 types\n",
    "# Happy Customer --> Positive\n",
    "# Potential New Customer --> Neutral\n",
    "# Lost Customer, Poor Service --> Negative\n",
    "\n",
    "df2['sentiment'] = ' '\n",
    "for i,cat in enumerate(df2.Category) :\n",
    "    if cat=='Happy Customer' :\n",
    "        df2['sentiment'][i] = 'positive'\n",
    "    elif cat=='Potential New Customer' :\n",
    "        df2['sentiment'][i] = 'neutral'\n",
    "    else :\n",
    "        df2['sentiment'][i] = 'negative'\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(67359, 2)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the duplicate data\n",
    "df2=df2.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted columns to equalise two data sets\n",
    "df2.drop(['Unnamed: 0','Category','text','Label'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                           tweet_clean sentiment\n1    it cofounder partner at team up group is a bus...   neutral\n3    it cofounder partner at team up group is a bus...   neutral\n4      you are to join a editorial learning by doing g   neutral\n6    with your in with our and measure your perform...   neutral\n8       your g speed hopefully you care about the also   neutral\n..                                                 ...       ...\n864  this is the second time the whole “ cutting se...  negative\n865  a if my part of people on my bill enough a fee...  negative\n866  i can call day in a row and get completely dif...  negative\n867           you dont have the best network doe right  negative\n868  you obviously get what you pay for stop being ...  positive\n\n[68228 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_clean</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>it cofounder partner at team up group is a bus...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>it cofounder partner at team up group is a bus...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>you are to join a editorial learning by doing g</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>with your in with our and measure your perform...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>your g speed hopefully you care about the also</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>864</th>\n      <td>this is the second time the whole “ cutting se...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>865</th>\n      <td>a if my part of people on my bill enough a fee...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>866</th>\n      <td>i can call day in a row and get completely dif...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>867</th>\n      <td>you dont have the best network doe right</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>868</th>\n      <td>you obviously get what you pay for stop being ...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>68228 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge two data sets\n",
    "df = pd.concat([df1,df2])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling\n",
    "df = df.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[\"tweet_clean\"], df[\"sentiment\"],test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize Words in each tweets (Encoding)\n",
    "# TfidfVectorizer converts text to word frequency vectors\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "tfidf_vectorizer.fit(df[\"tweet_clean\"])\n",
    "x_train_vector = tfidf_vectorizer.transform(x_train)\n",
    "x_test_vector = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy, Training Time\n",
    "def evaluate_metrics(y_test, y_hat, model_type,time):\n",
    "    \n",
    "    accuracy = accuracy_score(y_hat, y_test)\n",
    "    print(\"Model Type : \", model_type)\n",
    "    print(\"\\nAccuracy : \", format(accuracy, '.2f'))\n",
    "    print(\"\\nTraining Time : \", format(time, '.2f'), \"s\" )\n",
    "    print(\"\\n\", classification_report(y_hat, y_test))\n",
    "\n",
    "    # Generate Classification Report using Heat map\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.heatmap(confusion_matrix(y_hat, y_test), annot=True, fmt=\".2f\")\n",
    "    plt.show()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-42-dcdcd94089a2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mlogisticR_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mLogisticRegression\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mlogisticR_start\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mlogisticR_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train_vector\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[0mlogisticR_stop\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mlogisticR_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlogisticR_stop\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mlogisticR_start\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1415\u001B[0m                       \u001B[0mpenalty\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpenalty\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_squared_sum\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmax_squared_sum\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1416\u001B[0m                       sample_weight=sample_weight)\n\u001B[1;32m-> 1417\u001B[1;33m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001B[0m\u001B[0;32m   1418\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1419\u001B[0m         \u001B[0mfold_coefs_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_iter_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mfold_coefs_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1039\u001B[0m             \u001B[1;31m# remaining jobs.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1040\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1041\u001B[1;33m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1042\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1043\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    857\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    858\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 859\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    860\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    861\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    775\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    776\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 777\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    778\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    779\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    570\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    262\u001B[0m             return [func(*args, **kwargs)\n\u001B[1;32m--> 263\u001B[1;33m                     for func, args, kwargs in self.items]\n\u001B[0m\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    265\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__reduce__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    262\u001B[0m             return [func(*args, **kwargs)\n\u001B[1;32m--> 263\u001B[1;33m                     for func, args, kwargs in self.items]\n\u001B[0m\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    265\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__reduce__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001B[0m in \u001B[0;36m_logistic_regression_path\u001B[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001B[0m\n\u001B[0;32m    762\u001B[0m             n_iter_i = _check_optimize_result(\n\u001B[0;32m    763\u001B[0m                 \u001B[0msolver\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopt_res\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_iter\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 764\u001B[1;33m                 extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n\u001B[0m\u001B[0;32m    765\u001B[0m             \u001B[0mw0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mopt_res\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopt_res\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfun\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    766\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0msolver\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'newton-cg'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\optimize.py\u001B[0m in \u001B[0;36m_check_optimize_result\u001B[1;34m(solver, result, max_iter, extra_warning_msg)\u001B[0m\n\u001B[0;32m    241\u001B[0m                 \u001B[1;34m\"    https://scikit-learn.org/stable/modules/\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    242\u001B[0m                 \u001B[1;34m\"preprocessing.html\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 243\u001B[1;33m             ).format(solver, result.status, result.message.decode(\"latin1\"))\n\u001B[0m\u001B[0;32m    244\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextra_warning_msg\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    245\u001B[0m                 \u001B[0mwarning_msg\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;34m\"\\n\"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mextra_warning_msg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "# Maximum Entropy (Logistic Regression Algorithm)\n",
    "\n",
    "logisticR_model = LogisticRegression()\n",
    "logisticR_start = time.time()\n",
    "logisticR_model.fit(x_train_vector, y_train)\n",
    "logisticR_stop = time.time()\n",
    "logisticR_time = (logisticR_stop - logisticR_start)\n",
    "logisticR_preds = logisticR_model.predict(x_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticR_accuracy = evaluate_metrics(logisticR_preds, y_test, \"Logistic Regression Classifier\", logisticR_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Algorithm\n",
    "\n",
    "RandomForest_model = RandomForestClassifier()\n",
    "RandomForest_start = time.time()\n",
    "RandomForest_model.fit(x_train_vector, y_train)\n",
    "RandomForest_stop = time.time()\n",
    "RandomForest_time = (RandomForest_stop - RandomForest_start)\n",
    "RandomForest_preds = RandomForest_model.predict(x_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForest_accuracy = evaluate_metrics(RandomForest_preds, y_test, \"Random Forest Classifier\", RandomForest_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Algorithm\n",
    "\n",
    "DecisionTree_model = DecisionTreeClassifier(max_depth=20,random_state=0)\n",
    "DecisionTree_start = time.time()\n",
    "DecisionTree_model.fit(x_train_vector, y_train)\n",
    "DecisionTree_stop = time.time()\n",
    "DecisionTree_time = (DecisionTree_stop - DecisionTree_start)\n",
    "DecisionTree_pred = DecisionTree_model.predict(x_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTree_accuracy = evaluate_metrics(DecisionTree_pred, y_test, \"DecisionTree Classifier\", DecisionTree_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine Algorithm (Linear SVC classifier)\n",
    "\n",
    "svm_model = svm.SVC(kernel='linear')\n",
    "svm_start = time.time()\n",
    "svm_model.fit(x_train_vector, y_train)\n",
    "svm_stop = time.time()\n",
    "svm_time = (svm_stop - svm_start)\n",
    "svm_preds = svm_model.predict(x_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_accuracy = evaluate_metrics(svm_preds, y_test, \"Support Vector Machine\", svm_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes Algorithm\n",
    "\n",
    "MultinomialNB_model = MultinomialNB()\n",
    "MultinomialNB_start = time.time()\n",
    "MultinomialNB_model.fit(x_train_vector, y_train)\n",
    "MultinomialNB_stop = time.time()\n",
    "MultinomialNB_time = (MultinomialNB_stop - MultinomialNB_start)\n",
    "MultinomialNB_preds = MultinomialNB_model.predict(x_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultinomialNB_accuracy = evaluate_metrics(MultinomialNB_preds, y_test, \"Multinomial NB Classifier\", MultinomialNB_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph view of Accuracy\n",
    "\n",
    "x = [\"SVM\",\"Logistic Regression\",\"Random Forest\", \"DecisionTree Classifier\", \"Multinomial NB\"]\n",
    "y = [svm_accuracy,logisticR_accuracy,RandomForest_accuracy,DecisionTree_accuracy, MultinomialNB_accuracy]\n",
    "\n",
    "plt.bar(x=x, height=y)\n",
    "# Graph Title\n",
    "plt.title(\"Algorithms Accuracy\")\n",
    "# Label of Y axis\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(rotation=15)\n",
    "#Label of X axis\n",
    "plt.xlabel(\"Algorithm Model\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# x = [\"SVM\",\"Logistic Regression\",\"Random Forest\", \"DecisionTree Classifier\", \"Multinomial NB\"]\n",
    "# y = [svm_accuracy,logisticR_accuracy,RandomForest_accuracy,DecisionTree_accuracy, MultinomialNB_accuracy]\n",
    "#\n",
    "# piechart = plt.figure()\n",
    "# ax = piechart.add_axes([0,0,1,1])\n",
    "# ax.axis('equal')\n",
    "# ax.pie(y, labels = x,autopct='%1.2f%%')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save tfidf\n",
    "with open(\"tw_tfidf.pkl\", 'wb') as file:\n",
    "    pickle.dump(tfidf_vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "with open(\"tw_model.pkl\", 'wb') as file:\n",
    "    pickle.dump(svm_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Load and get Predictions - Should goes to the backend \n",
    "\n",
    "with open(\"tw_model.pkl\", 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "    \n",
    "with open(\"tw_tfidf.pkl\", 'rb') as file:\n",
    "    tfidf = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict --> Positive\n",
    "sentence = \"good service\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tfidf_vectorizer.transform([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(token)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict --> Neutral\n",
    "sentence = \"service\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tfidf_vectorizer.transform([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(token)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict --> Neutral\n",
    "sentence = \"bit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tfidf_vectorizer.transform([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(token)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict --> Positive\n",
    "sentence = \"good\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tfidf_vectorizer.transform([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(token)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict --> Negative\n",
    "sentence = \"worst service ever\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tfidf_vectorizer.transform([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(token)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict --> Neutral\n",
    "sentence = \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tfidf_vectorizer.transform([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(token)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict --> Positive\n",
    "sentence = \"telecommunication gives a good super service to their customers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tfidf_vectorizer.transform([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(token)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}